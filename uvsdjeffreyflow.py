# -*- coding: utf-8 -*-
"""UVSDJeffreyFlow.ipynb

AUTOMATICALLY GENERATED BY COLAB.
This was designed to run in coloab. 
Original file is located at
    https://colab.research.google.com/drive/1CPWylcGD-2hZOqxjYJbvZXeUbctsfiHk

we have already removed all images not 4095 by 2160
"""

# @title üõ†Ô∏è Setup Environment & Hardware Check
# @markdown Installs specific versions of Ultralytics, PyCOCOTools, and Hugging Face Hub.

import torch
import sys
import os

# Install dependencies
!pip install -q ultralytics pycocotools huggingface_hub opencv-python-headless tqdm

# Check GPU Status
print(f"python version: {sys.version}")
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    vram = torch.cuda.get_device_properties(0).total_memory / 1e9
    print(f"‚úÖ GPU Detected: {gpu_name}")
    print(f"   VRAM: {vram:.2f} GB")
    if "H100" in gpu_name or "A100" in gpu_name:
        print("   üöÄ High-Performance Runtime Active")
else:
    print("‚ö†Ô∏è No GPU detected. Go to Runtime > Change runtime type > T4/A100/H100 GPU")

# Create workspace directories
os.makedirs("input_data", exist_ok=True)
os.makedirs("output_data", exist_ok=True)
print("üìÇ Workspace ready.")

# @title üõ†Ô∏è Step 1: Install High-Performance Engine
# @markdown Installs the latest LMDeploy and Flash Attention.
!pip install -U -q lmdeploy flash-attn
!pip install -q pandas tqdm pillow

# @title üõ†Ô∏è Step 1b: Install Transformers & Utilities
!pip install -q transformers>=4.47.0 accelerate torchvision einops flash_attn

# @title üì• Download & Extract Data from Drive Link
# @markdown Installs `gdown` to download the folder directly, then unzips the data.

!pip install -U --no-cache-dir gdown --pre

# @title üì• Step 2: Smart Data Extraction
# @markdown Checks for local zip file first (to save time), then falls back to Google Drive.
import os
import zipfile
from google.colab import drive

# Paths to check
local_zip = "/content/dataset.zip"
drive_zip = "/content/drive/MyDrive/Zues_DataSets/UVSD_Tiled_640.zip"
input_data_dir = "/content/input_data"

os.makedirs(input_data_dir, exist_ok=True)

target_zip = None

# 1. Check Local File (Fastest - Prevents re-download)
if os.path.exists(local_zip):
    print(f"üì¶ Found local zip file: {local_zip}")
    target_zip = local_zip

# 2. Check Drive File (Fallback)
else:
    print(f"‚ö†Ô∏è Local file {local_zip} not found. Checking Google Drive...")
    if not os.path.exists('/content/drive'):
        print("üîå Mounting Google Drive...")
        drive.mount('/content/drive')

    if os.path.exists(drive_zip):
        print(f"üì¶ Found zip in Drive: {drive_zip}")
        target_zip = drive_zip

# 3. Extract
if target_zip:
    print(f"üìÇ Extracting {target_zip} to {input_data_dir}...")
    try:
        with zipfile.ZipFile(target_zip, 'r') as zip_ref:
            total = len(zip_ref.infolist())
            print(f"   Extracting {total} files (this may take a moment)...")
            zip_ref.extractall(input_data_dir)
        print("‚úÖ Extraction complete.")
    except Exception as e:
        print(f"‚ùå Error extracting: {e}")
else:
    print("‚ùå No zip file found locally or in Drive.")

# @title üïµÔ∏è‚Äç‚ôÄÔ∏è Check GPU Status
!nvidia-smi

# @title üìÇ Step 3: Locate Images & Unzip Nested Files
import os
import zipfile

base_dir = '/content/input_data'

# 1. Extract nested zip files
nested_zips = []
for root, dirs, files in os.walk(base_dir):
    for file in files:
        if file.endswith('.zip'):
            nested_zips.append(os.path.join(root, file))

for zip_path in nested_zips:
    print(f"Extracting nested zip: {zip_path}")
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(os.path.dirname(zip_path))
    except zipfile.BadZipFile:
        print(f"Failed to extract {zip_path}")

# 2. Locate annotation file and image directory
json_path = None
image_dir = None
candidate_dirs = []

for root, dirs, files in os.walk(base_dir):
    # Find annotation file
    if 'instances_val.json' in files:
        json_path = os.path.abspath(os.path.join(root, 'instances_val.json'))

    # Find image directory
    images = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    if images:
        candidate_dirs.append((os.path.abspath(root), len(images)))

# Choose the best image directory (prefer 'val' in name, then max image count)
best_dir = None
max_count = -1

for d, count in candidate_dirs:
    if best_dir is None:
        best_dir = d
        max_count = count
    else:
        # Prioritize 'val' in path
        curr_has_val = 'val' in d.lower()\n        best_has_val = 'val' in best_dir.lower()\n
        if curr_has_val and not best_has_val:
            best_dir = d
            max_count = count
        elif curr_has_val == best_has_val:
            # If both or neither have 'val', pick the one with more images
            if count > max_count:
                best_dir = d
                max_count = count

image_dir = best_dir

print(f"json_path: {json_path}")
print(f"image_dir: {image_dir}")

# @title üìÇ Step 3b: Verify/Fix Annotation Path
import os

# Check if json_path is None and look in /content
if json_path is None:
    potential_path = '/content/instances_val.json'
    if os.path.exists(potential_path):
        json_path = potential_path
        print(f"json_path updated to: {json_path}")
    else:
        # Fallback search in all content if needed, or report error
        print("Error: instances_val.json not found in /content/input_data or /content")

# Final verification
if json_path and os.path.exists(json_path):
    print(f"‚úÖ Annotation file found: {json_path}")
else:
    print("‚ùå Annotation file missing.")

if image_dir and os.path.isdir(image_dir):
    print(f"‚úÖ Image directory found: {image_dir}")
else:
    print("‚ùå Image directory missing.")

# @title üß† Step 4: Run AI Inference (InternVL)
# @markdown This cell loads the model and processes images in batches.

print("üîÑ Code Version: Test_Run_v4 (Fast Path)")

# --- üîß Auto-Fix for Numpy Conflict ---
try:
    import pandas as pd
    import numpy as np
except ImportError:
    pass
except ValueError:
    print("‚ö†Ô∏è NumPy version conflict detected. Downgrading NumPy to <2.0...")
    !pip install -q "numpy<2.0" --force-reinstall
    print("‚úÖ Numpy fixed. üîÑ PLEASE RESTART RUNTIME (Runtime > Restart session) and RUN THIS CELL AGAIN.")
    raise SystemExit("Stopping execution for restart.")

import json
import os
import torch
import shutil
from tqdm import tqdm
from lmdeploy import pipeline, TurbomindEngineConfig, GenerationConfig
from lmdeploy.vl import load_image
import accelerate.big_modeling

# --- üõ†Ô∏è HOTFIX: Patch Accelerate to handle Offloading ---
# lmdeploy doesn't pass the offload_folder down to the vision model loader,
# so we intercept the call and inject it manually.
_original_load = accelerate.big_modeling.load_checkpoint_and_dispatch

def patched_load_checkpoint_and_dispatch(model, checkpoint, **kwargs):
    if 'offload_folder' not in kwargs or kwargs['offload_folder'] is None:
        # Force the offload folder if missing
        kwargs['offload_folder'] = "offload_folder"
    return _original_load(model, checkpoint, **kwargs)

accelerate.big_modeling.load_checkpoint_and_dispatch = patched_load_checkpoint_and_dispatch
print("üõ†Ô∏è Applied patch to 'accelerate' to force offload_folder usage.")
# --------------------------------------------------------

# --- Configuration & Auto-Discovery ---
# Function to search for files/dirs if variables are lost
def find_file(name, search_path='/content'):
    for root, dirs, files in os.walk(search_path):
        if name in files:
            return os.path.join(root, name)
    return None

def find_dir_with_images(search_path='/content'):
    best_dir = None
    max_count = -1
    for root, dirs, files in os.walk(search_path):
        # Exclude hidden or system folders if needed
        images = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if len(images) > 0:
            if 'val' in root.lower() and (best_dir is None or 'val' not in best_dir.lower()):
                best_dir = root
                max_count = len(images)
            elif len(images) > max_count:
                best_dir = root
                max_count = len(images)
    return best_dir

# Recover json_path
if 'json_path' not in globals() or not json_path or not os.path.exists(json_path):
    print("üîç Searching for annotation file...")
    found_json = find_file('instances_val.json')
    if found_json:
        json_path = found_json
        print(f"‚úÖ Found annotations at: {json_path}")
    else:
        json_path = 'instances_val.json' # Fallback
        print("‚ö†Ô∏è Could not locate instances_val.json automatically.")

# Recover image_dir (Optimized)
# Check known paths first to avoid expensive search
known_paths = [
    '/content/input_data/YOLO_Dataset_Tiled_640/images/val',
    '/content/input_data/images/val'
]

if 'image_dir' not in globals() or not image_dir or not os.path.exists(image_dir):
    for p in known_paths:
        if os.path.exists(p):
            image_dir = p
            print(f"‚úÖ Found images at known path: {image_dir}")
            break

if 'image_dir' not in globals() or not image_dir or not os.path.exists(image_dir):
    print("üîç Searching for image directory (this may take a moment)...")
    found_dir = find_dir_with_images()
    if found_dir:
        image_dir = found_dir
        print(f"‚úÖ Found images at: {image_dir}")
    else:
        image_dir = 'input_data' # Fallback
        print("‚ö†Ô∏è Could not locate image directory automatically.")

ANNOTATION_FILE = json_path
IMAGE_DIR = image_dir
MODEL_PATH = 'OpenGVLab/InternVL2_5-26B'
OUTPUT_CSV = 'traffic_analysis_results.csv'

# --- Load Dataset ---
print(f"üìÇ Loading annotations from: {ANNOTATION_FILE}")
if not os.path.exists(ANNOTATION_FILE):
    print(f"‚ùå Error: Annotation file not found at {ANNOTATION_FILE}. Please run Step 2 or 3 again to download/extract data.")
else:
    with open(ANNOTATION_FILE, 'r') as f:
        coco_data = json.load(f)

    # Filter images that actually exist on disk
    valid_images = []
    for img in coco_data.get('images', []):
        fname = os.path.basename(img['file_name'])
        full_path = os.path.join(IMAGE_DIR, fname)
        if os.path.exists(full_path):
            valid_images.append({'id': img['id'], 'path': full_path, 'file_name': fname})

    print(f"‚úÖ Found {len(valid_images)} valid images in {IMAGE_DIR}")

    # --- Test Mode Toggle ---
    TEST_MODE = True # @param {type:"boolean"}
    TEST_COUNT = 8   # Number of images to test

    if TEST_MODE:
        valid_images = valid_images[:TEST_COUNT]
        print(f"‚ö†Ô∏è TEST MODE ACTIVE: Processing only the first {len(valid_images)} images.")

    # --- Model Setup ---
    print("üöÄ Initializing InternVL2.5 (High Performance)...")

    # Clear GPU cache to maximize available VRAM
    torch.cuda.empty_cache()

    # Prepare offload folder for Accelerate (Required for stability, even on H100)
    os.makedirs("offload_folder", exist_ok=True)

    # Configure Engine
    # H100 Optimization: Increased session_len and batch_size
    backend_config = TurbomindEngineConfig(session_len=4096, tp=1)
    gen_config = GenerationConfig(top_p=0.8, temperature=0.2, max_new_tokens=512)

    # Pass offload_folder to solve the Accelerate error
    pipe = pipeline(MODEL_PATH, backend_config=backend_config, offload_folder="offload_folder")
    print("‚úÖ Model Loaded Successfully!")

    # --- Prompt ---
    prompt = (
        "Analyze this traffic scene tile. Provide:\n"
        "1. Total car count.\n"
        "2. List of colors.\n"
        "3. Angle of view of the cars.\n"
        "4. Time of day.\n"
        "5. Camera angle (e.g., top-down, oblique).\n"
        "6. A brief description.\n"
        "Format output as JSON: {\"count\": int, \"colors\": [], \"time\": str, \"angle\": str, \"description\": str}"
    )

    # --- Inference Loop ---
    results = []
    batch_size = 8 # Optimized for H100 (80GB VRAM)
    save_interval = 1 # Save EVERY batch initially for immediate feedback

    print("üé• Starting Batch Inference...")
    print(f"   Processing {len(valid_images)} images in batches of {batch_size}...")

    for i in tqdm(range(0, len(valid_images), batch_size)):
        batch = valid_images[i:i+batch_size]

        try:
            loaded_imgs = [load_image(item['path']) for item in batch]
            inputs = [(prompt, img) for img in loaded_imgs]
            responses = pipe(inputs, gen_config=gen_config)

            for idx, resp in enumerate(responses):
                results.append({
                    "image_id": batch[idx]['id'],
                    "file_name": batch[idx]['file_name'],
                    "model_output": resp.text
                })

        except Exception as e:
            print(f"\n‚ùå Error processing batch {i}: {e}")
            continue

        # Progressive Saving
        # Save frequently at first (every batch), then less frequently (every 20 batches)
        if i < 20 or i % 20 == 0:
             pd.DataFrame(results).to_csv(OUTPUT_CSV, index=False)

    # --- Final Save ---
    df_results = pd.DataFrame(results)
    df_results.to_csv(OUTPUT_CSV, index=False)
    print(f"\n‚úÖ Done! Results saved to {OUTPUT_CSV}")
    display(df_results.head())

# @title üëÅÔ∏è Step 7: Visualize & Verify Results
# @markdown Displays 2 random images alongside their AI analysis for verification.
import matplotlib.pyplot as plt
from PIL import Image
import pandas as pd
import os

# Configuration
CSV_PATH = 'traffic_analysis_results.csv'

# Recover image_dir if missing (just in case)
if 'image_dir' not in globals() or not image_dir or not os.path.exists(image_dir):
    # Try known path
    potential_dir = '/content/input_data/YOLO_Dataset_Tiled_640/images/val'
    if os.path.exists(potential_dir):
        image_dir = potential_dir
    else:
        # Fallback search
        print("üîç Searching for image directory to visualize...")
        found = False
        for root, dirs, files in os.walk('/content/input_data'):
            if len([f for f in files if f.endswith('.jpg')]) > 0:
                image_dir = root
                found = True
                break
        if not found:
            print("‚ùå Could not find image directory. Please run Step 3 or 4 first.")
            image_dir = None

if os.path.exists(CSV_PATH) and image_dir:
    df = pd.read_csv(CSV_PATH)

    # --- FIX: Remove duplicates to ensure variety ---
    df = df.drop_duplicates(subset=['file_name'])

    if len(df) > 0:
        # Pick 2 random samples (or all if less than 2)
        num_samples = min(2, len(df))
        samples = df.sample(n=num_samples)

        print(f"üîç Showing {num_samples} distinct random examples for verification:\n")

        for index, row in samples.iterrows():
            img_name = row['file_name']
            model_out = row['model_output']
            full_path = os.path.join(image_dir, img_name)

            if os.path.exists(full_path):
                # Display Image
                img = Image.open(full_path)
                plt.figure(figsize=(10, 6))
                plt.imshow(img)
                plt.axis('off')
                plt.title(f"File: {img_name}")
                plt.show()

                # Display Text
                print(f"ü§ñ AI Analysis:\n{model_out}")
                print("="*80 + "\n")
            else:
                print(f"‚ùå Image file not found: {full_path}")
    else:
        print("‚ö†Ô∏è The results file is empty. Run Step 4 first.")
else:
    print(f"‚ùå Results file ({CSV_PATH}) not found. Please run Step 4 to generate data.")

import os
import pandas as pd

output_file = 'traffic_analysis_results.csv'

if os.path.exists(output_file):
    try:
        df = pd.read_csv(output_file)
        print(f"‚úÖ Output file found: {output_file}")
        print(f"üìä Rows processed so far: {len(df)}")
        print("\nPreview:")
        display(df.tail())
    except Exception as e:
        print(f"‚ö†Ô∏è File exists but could not be read (might be writing): {e}")
else:
    print("‚è≥ No output file found yet. Step 4 might still be initializing or running.")

# @title üßπ Step 5: Process & Clean Results
import pandas as pd
import json
import re
import time
import os

# Input/Output paths
INPUT_CSV = 'traffic_analysis_results.csv'
OUTPUT_ENRICHED_JSON = 'instances_val_enriched.json'

def parse_model_output(text):
    """Robustly extract JSON from model output string."""
    try:
        # Attempt direct JSON parse
        return json.loads(text)
    except:
        # If failed, try to find JSON block inside text
        try:
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                return json.loads(match.group())
        except:
            return None
    return None

# Check if file exists (User needs to run inference first)
if not os.path.exists(INPUT_CSV):
    print(f"‚ö†Ô∏è {INPUT_CSV} not found yet. Please run the inference cell above and wait for it to complete.")
else:
    print(f"üìÇ Loading results from {INPUT_CSV}...")
    df = pd.read_csv(INPUT_CSV)

    # Parse the 'model_output' column
    print("‚öôÔ∏è Parsing model outputs...")
    parsed_data = []
    for index, row in df.iterrows():
        raw_output = row.get('model_output', '')
        data = parse_model_output(raw_output)

        if data:
            # Flatten the dict
            entry = {
                'image_id': row.get('image_id'),
                'file_name': row.get('file_name'),
                'car_count': data.get('count', 0),
                'colors': ", ".join(data.get('colors', [])),
                'time_of_day': data.get('time', 'Unknown'),
                'angle': data.get('angle', 'Unknown'),
                'description': data.get('description', '')
            }
            parsed_data.append(entry)
        else:
            # Handle parsing failures
            parsed_data.append({
                'image_id': row.get('image_id'),
                'file_name': row.get('file_name'),
                'error': 'Parsing Failed'
            })

    # Create Clean DataFrame
    clean_df = pd.DataFrame(parsed_data)

    # Display Stats
    print(f"\nüìä Analysis Summary ({len(clean_df)} tiles):")
    if 'car_count' in clean_df.columns:
        print(f"   Total Cars Detected: {clean_df['car_count'].sum()}")
        print(f"   Avg Cars per Tile: {clean_df['car_count'].mean():.2f}")

    print("\n   Time of Day Distribution:")
    if 'time_of_day' in clean_df.columns:
        print(clean_df['time_of_day'].value_counts().head())

    # Save Cleaned Data
    clean_df.to_csv("traffic_analysis_clean.csv", index=False)
    print("\n‚úÖ Cleaned data saved to 'traffic_analysis_clean.csv'")
    display(clean_df.head())

# @title üíæ Step 6: Merge & Save Final Dataset
import json
import pandas as pd
import os

# Configuration
ORIGINAL_JSON = 'instances_val.json'  # or json_path variable from earlier
ANALYSIS_CSV = 'traffic_analysis_clean.csv'
OUTPUT_JSON = 'instances_val_enriched.json'

print(f"üîÑ Starting Merge Process...")

# 1. Check files
if not os.path.exists(ANALYSIS_CSV):
    print(f"‚ö†Ô∏è {ANALYSIS_CSV} not found. Please run the previous processing cell first.")
elif not os.path.exists(ORIGINAL_JSON):
    # Try using the variable if file not found at default path
    if 'json_path' in globals() and os.path.exists(json_path):
        ORIGINAL_JSON = json_path
    else:
        print(f"‚ùå Original JSON {ORIGINAL_JSON} not found.")
else:
    # 2. Load Data
    print(f"üìÇ Loading original annotations from {ORIGINAL_JSON}...")
    with open(ORIGINAL_JSON, 'r') as f:
        coco = json.load(f)

    print(f"üìÇ Loading analysis data from {ANALYSIS_CSV}...")
    df = pd.read_csv(ANALYSIS_CSV)

    # 3. Create Lookup Dictionary for Efficiency
    # Map image_id to the analysis row for fast access
    analysis_map = df.set_index('image_id').to_dict('index')

    # 4. Merge Attributes
    enriched_count = 0
    for img in coco['images']:
        img_id = img['id']
        if img_id in analysis_map:
            data = analysis_map[img_id]

            # Add new fields to the COCO image record
            img['attributes'] = {
                'detected_cars': int(data.get('car_count', 0)),
                'colors': data.get('colors', ''),
                'time_of_day': data.get('time_of_day', 'Unknown'),
                'angle': data.get('angle', 'Unknown'),
                'ai_description': data.get('description', '')
            }
            enriched_count += 1

    # 5. Save Enriched JSON
    print(f"üíæ Saving enriched dataset to {OUTPUT_JSON}...")
    with open(OUTPUT_JSON, 'w') as f:
        json.dump(coco, f, indent=2)

    print(f"‚úÖ Success! Enriched {enriched_count} images with AI attributes.")
    print(f"   New file: {os.path.abspath(OUTPUT_JSON)}")

image_files = [f for f in os.listdir(IMAGE_FOLDER) if f.endswith(('.jpg', '.png', '.jpeg'))]
results = []

# Process in batches of 8 for high throughput on A100/H100
batch_size = 8

for i in tqdm(range(0, len(image_files), batch_size)):
    batch_paths = [os.path.join(IMAGE_FOLDER, f) for f in image_files[i:i+batch_size]]
    images = [load_image(p) for p in batch_paths]

    # Run batch inference
    outputs = pipe( [(prompt, img) for img in images], gen_config=gen_config)

    for idx, out in enumerate(outputs):
        results.append({
            "filename": image_files[i+idx],
            "analysis": out.text
        })

    # Save every 100 images to prevent data loss
    if i % 100 == 0:
        pd.DataFrame(results).to_csv("traffic_analysis_backup.csv", index=False)

# Final Save
df = pd.DataFrame(results)
df.to_csv("final_traffic_analysis.csv", index=False)
print("Processing Complete!")

import os
import pandas as pd
from tqdm import tqdm
from lmdeploy import pipeline, TurbomindEngineConfig, GenerationConfig
from lmdeploy.vl import load_image

# Path to your images folder
IMAGE_FOLDER = "/content/your_images_folder"
model_path = 'OpenGVLab/InternVL2_5-26B'

# Engine Config: We limit 'session_len' to save VRAM for larger batches
# 'tp=1' for single GPU. If using a multi-GPU setup, increase this.
backend_config = TurbomindEngineConfig(session_len=2048, tp=1)
gen_config = GenerationConfig(top_p=0.8, temperature=0.2, max_new_tokens=256)

pipe = pipeline(model_path, backend_config=backend_config)

# System Prompt for consistent JSON-like output
prompt = (
    "Analyze the image and provide: "
    "1. Number of cars. 2. Color of each car. 3. Time of day. 4. Angle of view. "
    "5. A two-sentence description. Format: Number: [X], Colors: [List], "
    "Time: [X], Angle: [X], Description: [Two sentences]."
)

"""## execute_internvl_inference

### Subtask:
Install dependencies, set up the InternVL2.5 model using lmdeploy, and run inference on a sample of images defined in the annotation file.

## Summary:

### Q&A
**Question:** What are the resolved paths for the dataset's annotation file and image directory?
**Answer:** The annotation file was located at `/content/instances_val.json`, and the image directory was identified at `/content/input_data/YOLO_Dataset_Tiled_640/images/val`.

### Data Analysis Key Findings
*   The logic to inspect the input directory successfully filtered for valid image containers, prioritizing folders named 'val'. This resulted in selecting `/content/input_data/YOLO_Dataset_Tiled_640/images/val` as the primary image source.
*   The annotation file `instances_val.json` was not found within the extracted `/content/input_data` structure.
*   A fallback search mechanism successfully located the required `instances_val.json` file in the root directory `/content/`.

### Insights or Next Steps
*   The separation of the annotation file (root directory) from the image data (nested inside the YOLO dataset structure) requires careful path management for the subsequent inference steps.
*   With the `json_path` and `image_dir` variables successfully defined and verified, the workflow is ready to proceed with setting up the InternVL2.5 model for inference.
"""